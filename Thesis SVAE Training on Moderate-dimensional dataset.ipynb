{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1196404d",
   "metadata": {},
   "source": [
    "# SVAE Training on Moderate-dimensional Register Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add3f590",
   "metadata": {},
   "source": [
    "In this report, we will be training our SVAE models on moderate-dimensional dataset which is one of the two versions of register dataset used in this thesis. These are:\n",
    "\n",
    "- 1- High-dimensional Dataset: The dataset where we only removed features that are fully correlated and having zero variance\n",
    "- 2- Moderate-dimensional Dataset: The dataset where we removed features with correlation threshold of 0.9 and variance threshold of 1%.\n",
    "\n",
    "Each Dataset is trained with 5-Fold Cross-Validation method. The hyperparameters of SVAEs are trained in two steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd6f9d9",
   "metadata": {},
   "source": [
    "The hyperparameters of the **first step** are:\n",
    "- Number of Hidden Layers in Encoder/Decoder \n",
    "- Number of Neurons in Hidden Layers of Encoder/Decoder \n",
    "- Number of Hidden Layers in Classifier \n",
    "- Number of Neurons in Hidden Layers of Classifier \n",
    "- Latent Size \n",
    "\n",
    "The hyperparameters of the **second step** are:\n",
    "- alpha \n",
    "- beta \n",
    "- weight decay \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb55311",
   "metadata": {},
   "source": [
    "After finding best hyperparameters in the end of hyperparameter tuning, we will test the performance on validation test data which was not included in the validation training data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a647721",
   "metadata": {},
   "source": [
    "### Importing required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d8b273c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import argparse\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from custom_reg_dataset import RegisterDataset\n",
    "from datetime import datetime\n",
    "from timeit import default_timer as timer\n",
    "import time\n",
    "from statistics import mean as mean_calc\n",
    "\n",
    "import os\n",
    "\n",
    "import pytorch_warmup as warmup\n",
    "\n",
    "from models.SVAE import SVAE\n",
    "#from custom_dataset import TerraDataset\n",
    "from utils.loss_fn import loss_fn_SVAE\n",
    "\n",
    "from pytorchtools import EarlyStopping\n",
    "\n",
    "from training_methods import cv_fold_maker, hyperparameter_tuner, model_test,latent_corr_calc\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1c78da",
   "metadata": {},
   "source": [
    "## 1. Training on Moderate-dimensional Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56409643",
   "metadata": {},
   "source": [
    "In this part of the report, we will concentrate on the training of the moderate-dimensional dataset. Before starting training, we will set the device as GPU and prepare convert training data into dataloaders which will be used in training process of SVAEs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f1b9723",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f730473",
   "metadata": {},
   "source": [
    "Importing the validation training data and validation test data prepared for Moderate-dimensional dataset Training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b175197",
   "metadata": {},
   "outputs": [],
   "source": [
    "moddim_valtrain_5f = pd.read_csv(\"early_fusion_valtrain_5f_d365.txt\", sep = \"\\t\")\n",
    "moddim_valtest = pd.read_csv(\"early_fusion_valtest_d365.txt\", sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5d0c07",
   "metadata": {},
   "source": [
    "Preparing dataloaders for training folds and validation folds to be used in hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fb9dff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds = 5\n",
    "batch_size = 64\n",
    "\n",
    "moddim_Dataloader_list, moddim_dataset_val_list, moddims = cv_fold_maker(moddim_valtrain_5f, \n",
    "                                                                                   num_folds, batch_size, seed = seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeaa6dc6",
   "metadata": {},
   "source": [
    "Prepared data are moved to device(GPU) and added to lists which will be iterated throughout the 5-Fold Cross Validation.\n",
    "\n",
    "The order of folds in 5-Fold Cross Validation will be as in the following:\n",
    "- Training Folds: 2, 3, 4, 5 / Validation Fold: 1\n",
    "- Training Folds: 1, 3, 4, 5 / Validation Fold: 2\n",
    "- Training Folds: 1, 2, 4, 5 / Validation Fold: 3\n",
    "- Training Folds: 1, 2, 3, 5 / Validation Fold: 4\n",
    "- Training Folds: 1, 2, 3, 4 / Validation Fold: 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bffeb63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "moddim_X_val_list = []\n",
    "moddim_y_val_list = []\n",
    "\n",
    "for dataset in moddim_dataset_val_list:\n",
    "    X_val = dataset.x\n",
    "    X_val = X_val.to(device)\n",
    "    \n",
    "    y_val = dataset.y\n",
    "    y_val = y_val.to(device)\n",
    "    \n",
    "    moddim_X_val_list.append(X_val)\n",
    "    moddim_y_val_list.append(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aafd02e",
   "metadata": {},
   "source": [
    "In above code, we create lists for validation fold data and validaton fold labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502802ca",
   "metadata": {},
   "source": [
    "### 1.1 Hyperparameter Tuning Step 1: NN Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7309053b",
   "metadata": {},
   "source": [
    "In this first step of hyperparameter tuning, we will tune the hyperparameters related to Neural Network Architectures.\n",
    "\n",
    "The parameters which will be stable throughout this hyperparameter tuning step are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5ca3941",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_list = [64]\n",
    "w_decay_list = [10**-4]\n",
    "alpha_list = [1]\n",
    "beta_list = [1]\n",
    "lr_list= [0.001]\n",
    "es_thr = 100 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7d34f5",
   "metadata": {},
   "source": [
    "The parameters which will be tuned in this hyperparameter tuning step are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b85d12a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder number of layers = 1, 3, 5 / encoder number of neurons each layer = 128, 256, 512\n",
    "encoder_layer_list = [[moddims, 128], [moddims, 256], [moddims, 512], [moddims, 128, 128, 128], \\\n",
    "                      [moddims, 256, 256, 256], [moddims, 512, 512, 512], [moddims, 128, 128, 128, 128, 128] ,\\\n",
    "                     [moddims, 256, 256, 256, 256, 256], [moddims, 512, 512, 512, 512, 512]]\n",
    "#classifier number of layers = 1, 3, 5 / classifier number of neurons each layer = 128, 256, 512\n",
    "classifier_layer_list = [[128, 1], [256, 1], [512, 1], [128,128,128, 1], [256,256,256, 1], [512, 512, 512, 1],\\\n",
    "                        [128, 128, 128, 128, 128, 1], [256, 256, 256, 256, 256, 1], [512, 512, 512, 512, 512, 1]]\n",
    "#number of dimensions in the latent space\n",
    "latent_size_list = [2, 8, 32, 64, 128]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049d136d",
   "metadata": {},
   "source": [
    "Now we will use *hyperparameter_tuning* function in order to train SVAE models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aaf81cd5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training start date is: 2023-05-09 12:00:00.112283\n",
      "./net_weights/SVAE_models_09-05-2023_12-00-00 directory is created\n",
      "09-05-2023_12-00-00_loss_logs directory is created under H:\\Projects\\My Thesis\\loss_values\\\n",
      "1 settings have been checked and saved to report file\n",
      "6 settings have been checked and saved to report file\n",
      "11 settings have been checked and saved to report file\n",
      "16 settings have been checked and saved to report file\n",
      "21 settings have been checked and saved to report file\n",
      "26 settings have been checked and saved to report file\n",
      "31 settings have been checked and saved to report file\n",
      "36 settings have been checked and saved to report file\n",
      "41 settings have been checked and saved to report file\n",
      "46 settings have been checked and saved to report file\n",
      "51 settings have been checked and saved to report file\n",
      "56 settings have been checked and saved to report file\n",
      "61 settings have been checked and saved to report file\n",
      "66 settings have been checked and saved to report file\n",
      "71 settings have been checked and saved to report file\n",
      "76 settings have been checked and saved to report file\n",
      "81 settings have been checked and saved to report file\n",
      "86 settings have been checked and saved to report file\n",
      "91 settings have been checked and saved to report file\n",
      "96 settings have been checked and saved to report file\n",
      "101 settings have been checked and saved to report file\n",
      "106 settings have been checked and saved to report file\n",
      "111 settings have been checked and saved to report file\n",
      "116 settings have been checked and saved to report file\n",
      "121 settings have been checked and saved to report file\n",
      "126 settings have been checked and saved to report file\n",
      "131 settings have been checked and saved to report file\n",
      "136 settings have been checked and saved to report file\n",
      "141 settings have been checked and saved to report file\n",
      "146 settings have been checked and saved to report file\n",
      "151 settings have been checked and saved to report file\n",
      "156 settings have been checked and saved to report file\n",
      "161 settings have been checked and saved to report file\n",
      "166 settings have been checked and saved to report file\n",
      "171 settings have been checked and saved to report file\n",
      "176 settings have been checked and saved to report file\n",
      "181 settings have been checked and saved to report file\n",
      "186 settings have been checked and saved to report file\n",
      "191 settings have been checked and saved to report file\n",
      "196 settings have been checked and saved to report file\n",
      "201 settings have been checked and saved to report file\n",
      "206 settings have been checked and saved to report file\n",
      "211 settings have been checked and saved to report file\n",
      "216 settings have been checked and saved to report file\n",
      "221 settings have been checked and saved to report file\n",
      "226 settings have been checked and saved to report file\n",
      "231 settings have been checked and saved to report file\n",
      "236 settings have been checked and saved to report file\n",
      "241 settings have been checked and saved to report file\n",
      "246 settings have been checked and saved to report file\n",
      "251 settings have been checked and saved to report file\n",
      "256 settings have been checked and saved to report file\n",
      "261 settings have been checked and saved to report file\n",
      "266 settings have been checked and saved to report file\n",
      "271 settings have been checked and saved to report file\n",
      "276 settings have been checked and saved to report file\n",
      "281 settings have been checked and saved to report file\n",
      "286 settings have been checked and saved to report file\n",
      "291 settings have been checked and saved to report file\n",
      "296 settings have been checked and saved to report file\n",
      "301 settings have been checked and saved to report file\n",
      "306 settings have been checked and saved to report file\n",
      "311 settings have been checked and saved to report file\n",
      "316 settings have been checked and saved to report file\n",
      "321 settings have been checked and saved to report file\n",
      "326 settings have been checked and saved to report file\n",
      "331 settings have been checked and saved to report file\n",
      "336 settings have been checked and saved to report file\n",
      "341 settings have been checked and saved to report file\n",
      "346 settings have been checked and saved to report file\n",
      "351 settings have been checked and saved to report file\n",
      "356 settings have been checked and saved to report file\n",
      "361 settings have been checked and saved to report file\n",
      "366 settings have been checked and saved to report file\n",
      "371 settings have been checked and saved to report file\n",
      "376 settings have been checked and saved to report file\n",
      "381 settings have been checked and saved to report file\n",
      "386 settings have been checked and saved to report file\n",
      "391 settings have been checked and saved to report file\n",
      "396 settings have been checked and saved to report file\n",
      "401 settings have been checked and saved to report file\n",
      "Training end date is: 2023-05-14 08:51:22.934801\n",
      "Total Training Time is: 20:51:17\n"
     ]
    }
   ],
   "source": [
    "moddim_report_step1,moddim_loss_step1_list, moddim_loss_step1_names = hyperparameter_tuner(device, moddims, \n",
    "                        num_folds, moddim_Dataloader_list, moddim_X_val_list, moddim_y_val_list, batch_size_list,\n",
    "                        w_decay_list, alpha_list, beta_list, lr_list,\n",
    "                        encoder_layer_list, classifier_layer_list, latent_size_list, seed = seed, es_thr = es_thr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfd50c3",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning Step 1 Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fee1172",
   "metadata": {},
   "source": [
    "#### Mean Auroc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a84d0163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model_number</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Batch_size</th>\n",
       "      <th>Encoder_num_neurons</th>\n",
       "      <th>Encoder_num_hidden_layers</th>\n",
       "      <th>Clf_num_neurons</th>\n",
       "      <th>Clf_num_hidden_layers</th>\n",
       "      <th>Latent_size</th>\n",
       "      <th>Alpha</th>\n",
       "      <th>Beta</th>\n",
       "      <th>...</th>\n",
       "      <th>CV3_val_acc</th>\n",
       "      <th>CV4_val_acc</th>\n",
       "      <th>CV5_val_acc</th>\n",
       "      <th>CV1_val_auroc</th>\n",
       "      <th>CV2_val_auroc</th>\n",
       "      <th>CV3_val_auroc</th>\n",
       "      <th>CV4_val_auroc</th>\n",
       "      <th>CV5_val_auroc</th>\n",
       "      <th>CV_avg_val_acc</th>\n",
       "      <th>CV_avg_val_auroc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>386</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>512</td>\n",
       "      <td>5</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.559664</td>\n",
       "      <td>0.548523</td>\n",
       "      <td>0.597315</td>\n",
       "      <td>0.592145</td>\n",
       "      <td>0.584928</td>\n",
       "      <td>0.561317</td>\n",
       "      <td>0.582234</td>\n",
       "      <td>0.567565</td>\n",
       "      <td>0.586066</td>\n",
       "      <td>0.577638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>372</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>512</td>\n",
       "      <td>5</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.545148</td>\n",
       "      <td>0.540268</td>\n",
       "      <td>0.565559</td>\n",
       "      <td>0.592664</td>\n",
       "      <td>0.589434</td>\n",
       "      <td>0.584457</td>\n",
       "      <td>0.552096</td>\n",
       "      <td>0.556779</td>\n",
       "      <td>0.576842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>376</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>512</td>\n",
       "      <td>5</td>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.597479</td>\n",
       "      <td>0.605907</td>\n",
       "      <td>0.545302</td>\n",
       "      <td>0.579730</td>\n",
       "      <td>0.588451</td>\n",
       "      <td>0.568125</td>\n",
       "      <td>0.582750</td>\n",
       "      <td>0.564865</td>\n",
       "      <td>0.586445</td>\n",
       "      <td>0.576784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>381</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>512</td>\n",
       "      <td>5</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.589030</td>\n",
       "      <td>0.611577</td>\n",
       "      <td>0.570604</td>\n",
       "      <td>0.576072</td>\n",
       "      <td>0.565526</td>\n",
       "      <td>0.588725</td>\n",
       "      <td>0.582581</td>\n",
       "      <td>0.596834</td>\n",
       "      <td>0.576702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>371</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>512</td>\n",
       "      <td>5</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.605042</td>\n",
       "      <td>0.591561</td>\n",
       "      <td>0.622483</td>\n",
       "      <td>0.588084</td>\n",
       "      <td>0.573887</td>\n",
       "      <td>0.569028</td>\n",
       "      <td>0.583299</td>\n",
       "      <td>0.568109</td>\n",
       "      <td>0.606253</td>\n",
       "      <td>0.576481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>104</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.515126</td>\n",
       "      <td>0.559494</td>\n",
       "      <td>0.541107</td>\n",
       "      <td>0.526765</td>\n",
       "      <td>0.538730</td>\n",
       "      <td>0.520160</td>\n",
       "      <td>0.542355</td>\n",
       "      <td>0.546980</td>\n",
       "      <td>0.538080</td>\n",
       "      <td>0.534998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.509244</td>\n",
       "      <td>0.530802</td>\n",
       "      <td>0.531040</td>\n",
       "      <td>0.518152</td>\n",
       "      <td>0.566891</td>\n",
       "      <td>0.521373</td>\n",
       "      <td>0.531604</td>\n",
       "      <td>0.529682</td>\n",
       "      <td>0.520706</td>\n",
       "      <td>0.533540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.537553</td>\n",
       "      <td>0.537752</td>\n",
       "      <td>0.535126</td>\n",
       "      <td>0.539710</td>\n",
       "      <td>0.549390</td>\n",
       "      <td>0.525106</td>\n",
       "      <td>0.514159</td>\n",
       "      <td>0.534168</td>\n",
       "      <td>0.532698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>147</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.542017</td>\n",
       "      <td>0.547679</td>\n",
       "      <td>0.534396</td>\n",
       "      <td>0.511313</td>\n",
       "      <td>0.542907</td>\n",
       "      <td>0.528851</td>\n",
       "      <td>0.536483</td>\n",
       "      <td>0.536702</td>\n",
       "      <td>0.538227</td>\n",
       "      <td>0.531251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.523529</td>\n",
       "      <td>0.552743</td>\n",
       "      <td>0.539430</td>\n",
       "      <td>0.516514</td>\n",
       "      <td>0.546957</td>\n",
       "      <td>0.515933</td>\n",
       "      <td>0.541958</td>\n",
       "      <td>0.534390</td>\n",
       "      <td>0.536891</td>\n",
       "      <td>0.531150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>405 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model_number  Seed  Batch_size  Encoder_num_neurons  \\\n",
       "385           386     1          64                  512   \n",
       "371           372     1          64                  512   \n",
       "375           376     1          64                  512   \n",
       "380           381     1          64                  512   \n",
       "370           371     1          64                  512   \n",
       "..            ...   ...         ...                  ...   \n",
       "103           104     1          64                  512   \n",
       "61             62     1          64                  256   \n",
       "8               9     1          64                  128   \n",
       "146           147     1          64                  128   \n",
       "93             94     1          64                  512   \n",
       "\n",
       "     Encoder_num_hidden_layers  Clf_num_neurons  Clf_num_hidden_layers  \\\n",
       "385                          5              512                      3   \n",
       "371                          5              512                      1   \n",
       "375                          5              128                      3   \n",
       "380                          5              256                      3   \n",
       "370                          5              512                      1   \n",
       "..                         ...              ...                    ...   \n",
       "103                          1              512                      1   \n",
       "61                           1              128                      3   \n",
       "8                            1              256                      1   \n",
       "146                          3              512                      1   \n",
       "93                           1              128                      1   \n",
       "\n",
       "     Latent_size  Alpha  Beta  ...  CV3_val_acc  CV4_val_acc  CV5_val_acc  \\\n",
       "385            2      1     1  ...     0.559664     0.548523     0.597315   \n",
       "371            8      1     1  ...     0.542857     0.545148     0.540268   \n",
       "375            2      1     1  ...     0.597479     0.605907     0.545302   \n",
       "380            2      1     1  ...     0.588235     0.589030     0.611577   \n",
       "370            2      1     1  ...     0.605042     0.591561     0.622483   \n",
       "..           ...    ...   ...  ...          ...          ...          ...   \n",
       "103           64      1     1  ...     0.515126     0.559494     0.541107   \n",
       "61             8      1     1  ...     0.509244     0.530802     0.531040   \n",
       "8             64      1     1  ...     0.542857     0.537553     0.537752   \n",
       "146            8      1     1  ...     0.542017     0.547679     0.534396   \n",
       "93            64      1     1  ...     0.523529     0.552743     0.539430   \n",
       "\n",
       "     CV1_val_auroc  CV2_val_auroc  CV3_val_auroc  CV4_val_auroc  \\\n",
       "385       0.592145       0.584928       0.561317       0.582234   \n",
       "371       0.565559       0.592664       0.589434       0.584457   \n",
       "375       0.579730       0.588451       0.568125       0.582750   \n",
       "380       0.570604       0.576072       0.565526       0.588725   \n",
       "370       0.588084       0.573887       0.569028       0.583299   \n",
       "..             ...            ...            ...            ...   \n",
       "103       0.526765       0.538730       0.520160       0.542355   \n",
       "61        0.518152       0.566891       0.521373       0.531604   \n",
       "8         0.535126       0.539710       0.549390       0.525106   \n",
       "146       0.511313       0.542907       0.528851       0.536483   \n",
       "93        0.516514       0.546957       0.515933       0.541958   \n",
       "\n",
       "     CV5_val_auroc  CV_avg_val_acc  CV_avg_val_auroc  \n",
       "385       0.567565        0.586066          0.577638  \n",
       "371       0.552096        0.556779          0.576842  \n",
       "375       0.564865        0.586445          0.576784  \n",
       "380       0.582581        0.596834          0.576702  \n",
       "370       0.568109        0.606253          0.576481  \n",
       "..             ...             ...               ...  \n",
       "103       0.546980        0.538080          0.534998  \n",
       "61        0.529682        0.520706          0.533540  \n",
       "8         0.514159        0.534168          0.532698  \n",
       "146       0.536702        0.538227          0.531251  \n",
       "93        0.534390        0.536891          0.531150  \n",
       "\n",
       "[405 rows x 54 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moddim_report_step1.sort_values(by=[\"CV_avg_val_auroc\"], ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664d0991",
   "metadata": {},
   "source": [
    "Based on the results the best settings we got from the step 1 hyperparameter tuning are:\n",
    "\n",
    "- Number of Hidden Layers in Encoder/Decoder = 5\n",
    "- Number of Neurons in Hidden Layers of Encoder/Decoder = 512\n",
    "- Number of Hidden Layers in Classifier = 3\n",
    "- Number of Neurons in Hidden Layers of Classifier = 512\n",
    "- Latent Size = 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa7148f",
   "metadata": {},
   "source": [
    "### 1.2 Hyperparameter Tuning Step 2: Loss Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e45ec6",
   "metadata": {},
   "source": [
    "In this second step of hyperparameter tuning, we will tune the loss hyperparameters such as weight decay used for regularization and loss calculation parameters alpha and beta.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926359f9",
   "metadata": {},
   "source": [
    "The parameters which will be stable throughout this hyperparameter tuning step are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5fbdf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_list = [64]\n",
    "lr_list= [0.001]\n",
    "es_thr = 100 \n",
    "\n",
    "#Best values for number of nodes and hidden layers found for encoder/decoder in first tuning step was:\n",
    "encoder_layer_list = [[moddims, 512, 512, 512, 512, 512]]\n",
    "#Best values for number of nodes and hidden layers found for classifier in first tuning step was:\n",
    "classifier_layer_list = [[512, 512, 512, 1]]\n",
    "\n",
    "latent_size_list = [2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08c0e75",
   "metadata": {},
   "source": [
    "The parameters which will be tuned in this hyperparameter tuning step are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "731c05fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_decay_list = [1, 10**-2, 10**-4, 10**-6]\n",
    "alpha_list = [0.1, 1, 10, 100]\n",
    "beta_list = [0.1, 1, 10, 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7836a4b",
   "metadata": {},
   "source": [
    "Now we will use *hyperparameter_tuning* function in order to train SVAE models based on the results we got from first step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "611cf527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training start date is: 2023-05-14 10:17:16.833348\n",
      "./net_weights/SVAE_models_14-05-2023_10-17-16 directory is created\n",
      "14-05-2023_10-17-16_loss_logs directory is created under H:\\Projects\\My Thesis\\loss_values\\\n",
      "1 settings have been checked and saved to report file\n",
      "6 settings have been checked and saved to report file\n",
      "11 settings have been checked and saved to report file\n",
      "16 settings have been checked and saved to report file\n",
      "21 settings have been checked and saved to report file\n",
      "26 settings have been checked and saved to report file\n",
      "31 settings have been checked and saved to report file\n",
      "36 settings have been checked and saved to report file\n",
      "41 settings have been checked and saved to report file\n",
      "46 settings have been checked and saved to report file\n",
      "51 settings have been checked and saved to report file\n",
      "56 settings have been checked and saved to report file\n",
      "61 settings have been checked and saved to report file\n",
      "Training end date is: 2023-05-15 09:52:02.933204\n",
      "Total Training Time is: 23:34:45\n"
     ]
    }
   ],
   "source": [
    "moddim_report_step2,moddim_loss_step2_list, moddim_loss_step2_names = hyperparameter_tuner(device, moddims, \n",
    "                        num_folds, moddim_Dataloader_list, moddim_X_val_list, moddim_y_val_list, batch_size_list,\n",
    "                        w_decay_list, alpha_list, beta_list, lr_list,\n",
    "                        encoder_layer_list, classifier_layer_list, latent_size_list, seed = seed, es_thr = es_thr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2210859",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning Step 2 Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ab8c6d",
   "metadata": {},
   "source": [
    "####  Mean Auroc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33581c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model_number</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Batch_size</th>\n",
       "      <th>Encoder_num_neurons</th>\n",
       "      <th>Encoder_num_hidden_layers</th>\n",
       "      <th>Clf_num_neurons</th>\n",
       "      <th>Clf_num_hidden_layers</th>\n",
       "      <th>Latent_size</th>\n",
       "      <th>Alpha</th>\n",
       "      <th>Beta</th>\n",
       "      <th>...</th>\n",
       "      <th>CV3_val_acc</th>\n",
       "      <th>CV4_val_acc</th>\n",
       "      <th>CV5_val_acc</th>\n",
       "      <th>CV1_val_auroc</th>\n",
       "      <th>CV2_val_auroc</th>\n",
       "      <th>CV3_val_auroc</th>\n",
       "      <th>CV4_val_auroc</th>\n",
       "      <th>CV5_val_auroc</th>\n",
       "      <th>CV_avg_val_acc</th>\n",
       "      <th>CV_avg_val_auroc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>512</td>\n",
       "      <td>5</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.562185</td>\n",
       "      <td>0.556118</td>\n",
       "      <td>0.547819</td>\n",
       "      <td>0.586805</td>\n",
       "      <td>0.589227</td>\n",
       "      <td>0.588417</td>\n",
       "      <td>0.571800</td>\n",
       "      <td>0.573130</td>\n",
       "      <td>0.550006</td>\n",
       "      <td>0.581876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>512</td>\n",
       "      <td>5</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.567227</td>\n",
       "      <td>0.565401</td>\n",
       "      <td>0.536074</td>\n",
       "      <td>0.582728</td>\n",
       "      <td>0.590380</td>\n",
       "      <td>0.587681</td>\n",
       "      <td>0.582791</td>\n",
       "      <td>0.563522</td>\n",
       "      <td>0.555584</td>\n",
       "      <td>0.581420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>512</td>\n",
       "      <td>5</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.599160</td>\n",
       "      <td>0.627848</td>\n",
       "      <td>0.621644</td>\n",
       "      <td>0.564725</td>\n",
       "      <td>0.579616</td>\n",
       "      <td>0.584365</td>\n",
       "      <td>0.587660</td>\n",
       "      <td>0.580596</td>\n",
       "      <td>0.609641</td>\n",
       "      <td>0.579392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>512</td>\n",
       "      <td>5</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.531092</td>\n",
       "      <td>0.591561</td>\n",
       "      <td>0.578859</td>\n",
       "      <td>0.577849</td>\n",
       "      <td>0.592664</td>\n",
       "      <td>0.564212</td>\n",
       "      <td>0.587058</td>\n",
       "      <td>0.567257</td>\n",
       "      <td>0.565871</td>\n",
       "      <td>0.577808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>512</td>\n",
       "      <td>5</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.606723</td>\n",
       "      <td>0.627004</td>\n",
       "      <td>0.626678</td>\n",
       "      <td>0.577283</td>\n",
       "      <td>0.598545</td>\n",
       "      <td>0.568620</td>\n",
       "      <td>0.578087</td>\n",
       "      <td>0.564303</td>\n",
       "      <td>0.612321</td>\n",
       "      <td>0.577368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>512</td>\n",
       "      <td>5</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.591597</td>\n",
       "      <td>0.561181</td>\n",
       "      <td>0.593960</td>\n",
       "      <td>0.540317</td>\n",
       "      <td>0.569025</td>\n",
       "      <td>0.538684</td>\n",
       "      <td>0.548981</td>\n",
       "      <td>0.551751</td>\n",
       "      <td>0.582337</td>\n",
       "      <td>0.549752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>512</td>\n",
       "      <td>5</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.569748</td>\n",
       "      <td>0.599156</td>\n",
       "      <td>0.620805</td>\n",
       "      <td>0.544558</td>\n",
       "      <td>0.560220</td>\n",
       "      <td>0.542075</td>\n",
       "      <td>0.543694</td>\n",
       "      <td>0.554033</td>\n",
       "      <td>0.591099</td>\n",
       "      <td>0.548916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>512</td>\n",
       "      <td>5</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.577311</td>\n",
       "      <td>0.594937</td>\n",
       "      <td>0.608221</td>\n",
       "      <td>0.549796</td>\n",
       "      <td>0.554344</td>\n",
       "      <td>0.533520</td>\n",
       "      <td>0.544057</td>\n",
       "      <td>0.560653</td>\n",
       "      <td>0.590429</td>\n",
       "      <td>0.548474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>512</td>\n",
       "      <td>5</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.594118</td>\n",
       "      <td>0.583122</td>\n",
       "      <td>0.603188</td>\n",
       "      <td>0.545299</td>\n",
       "      <td>0.564622</td>\n",
       "      <td>0.538142</td>\n",
       "      <td>0.560902</td>\n",
       "      <td>0.532140</td>\n",
       "      <td>0.581988</td>\n",
       "      <td>0.548221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>512</td>\n",
       "      <td>5</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.609244</td>\n",
       "      <td>0.629536</td>\n",
       "      <td>0.619966</td>\n",
       "      <td>0.528572</td>\n",
       "      <td>0.541071</td>\n",
       "      <td>0.549550</td>\n",
       "      <td>0.541195</td>\n",
       "      <td>0.541282</td>\n",
       "      <td>0.614694</td>\n",
       "      <td>0.540334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model_number Seed Batch_size Encoder_num_neurons Encoder_num_hidden_layers  \\\n",
       "9            10    1         64                 512                         5   \n",
       "10           11    1         64                 512                         5   \n",
       "38           39    1         64                 512                         5   \n",
       "20           21    1         64                 512                         5   \n",
       "50           51    1         64                 512                         5   \n",
       "..          ...  ...        ...                 ...                       ...   \n",
       "56           57    1         64                 512                         5   \n",
       "44           45    1         64                 512                         5   \n",
       "60           61    1         64                 512                         5   \n",
       "30           31    1         64                 512                         5   \n",
       "3             4    1         64                 512                         5   \n",
       "\n",
       "   Clf_num_neurons Clf_num_hidden_layers Latent_size  Alpha   Beta  ...  \\\n",
       "9              512                     3           2   10.0    1.0  ...   \n",
       "10             512                     3           2   10.0   10.0  ...   \n",
       "38             512                     3           2    1.0   10.0  ...   \n",
       "20             512                     3           2    1.0    0.1  ...   \n",
       "50             512                     3           2    0.1   10.0  ...   \n",
       "..             ...                   ...         ...    ...    ...  ...   \n",
       "56             512                     3           2   10.0    0.1  ...   \n",
       "44             512                     3           2  100.0    0.1  ...   \n",
       "60             512                     3           2  100.0    0.1  ...   \n",
       "30             512                     3           2  100.0   10.0  ...   \n",
       "3              512                     3           2    0.1  100.0  ...   \n",
       "\n",
       "    CV3_val_acc CV4_val_acc  CV5_val_acc  CV1_val_auroc  CV2_val_auroc  \\\n",
       "9      0.562185    0.556118     0.547819       0.586805       0.589227   \n",
       "10     0.567227    0.565401     0.536074       0.582728       0.590380   \n",
       "38     0.599160    0.627848     0.621644       0.564725       0.579616   \n",
       "20     0.531092    0.591561     0.578859       0.577849       0.592664   \n",
       "50     0.606723    0.627004     0.626678       0.577283       0.598545   \n",
       "..          ...         ...          ...            ...            ...   \n",
       "56     0.591597    0.561181     0.593960       0.540317       0.569025   \n",
       "44     0.569748    0.599156     0.620805       0.544558       0.560220   \n",
       "60     0.577311    0.594937     0.608221       0.549796       0.554344   \n",
       "30     0.594118    0.583122     0.603188       0.545299       0.564622   \n",
       "3      0.609244    0.629536     0.619966       0.528572       0.541071   \n",
       "\n",
       "    CV3_val_auroc  CV4_val_auroc  CV5_val_auroc  CV_avg_val_acc  \\\n",
       "9        0.588417       0.571800       0.573130        0.550006   \n",
       "10       0.587681       0.582791       0.563522        0.555584   \n",
       "38       0.584365       0.587660       0.580596        0.609641   \n",
       "20       0.564212       0.587058       0.567257        0.565871   \n",
       "50       0.568620       0.578087       0.564303        0.612321   \n",
       "..            ...            ...            ...             ...   \n",
       "56       0.538684       0.548981       0.551751        0.582337   \n",
       "44       0.542075       0.543694       0.554033        0.591099   \n",
       "60       0.533520       0.544057       0.560653        0.590429   \n",
       "30       0.538142       0.560902       0.532140        0.581988   \n",
       "3        0.549550       0.541195       0.541282        0.614694   \n",
       "\n",
       "    CV_avg_val_auroc  \n",
       "9           0.581876  \n",
       "10          0.581420  \n",
       "38          0.579392  \n",
       "20          0.577808  \n",
       "50          0.577368  \n",
       "..               ...  \n",
       "56          0.549752  \n",
       "44          0.548916  \n",
       "60          0.548474  \n",
       "30          0.548221  \n",
       "3           0.540334  \n",
       "\n",
       "[64 rows x 54 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moddim_report_step2.sort_values(by=[\"CV_avg_val_auroc\"], ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e349e6f8",
   "metadata": {},
   "source": [
    "Based on the results the best settings we got from the step 2 hyperparameter tuning are:\n",
    "\n",
    "- alpha = 10\n",
    "- beta = 1\n",
    "- weight decay = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be4a81f",
   "metadata": {},
   "source": [
    "### 1.3 Moderate-dimensional Data Hyperparameter Tuning Result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7071cbaa",
   "metadata": {},
   "source": [
    "\n",
    "In the end, the best SVAE hyperparameter values for the moderate-dimensional dataset are:\n",
    "\n",
    "- Number of Hidden Layers in Encoder/Decoder = 5\n",
    "- Number of Neurons in Hidden Layers of Encoder/Decoder = 512\n",
    "- Number of Hidden Layers in Classifier = 3\n",
    "- Number of Neurons in Hidden Layers of Classifier = 512\n",
    "- Latent Size = 2\n",
    "- alpha = 10\n",
    "- beta = 1\n",
    "- weight decay = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4954238",
   "metadata": {},
   "source": [
    "## 2. Testing on Validation Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddc2277",
   "metadata": {},
   "source": [
    "As we have found the best SVAE hyperparameter values for moderate-dimensional dataset, we can check its performance on validation test data which was not included in hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3100b6d",
   "metadata": {},
   "source": [
    "### 2.1 Testing on Validation Test Data for Moderate-dimensional Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfcf8f8",
   "metadata": {},
   "source": [
    "- Number of Hidden Layers in Encoder/Decoder = 5\n",
    "- Number of Neurons in Hidden Layers of Encoder/Decoder = 512\n",
    "- Number of Hidden Layers in Classifier = 3\n",
    "- Number of Neurons in Hidden Layers of Classifier = 512\n",
    "- Latent Size = 2\n",
    "- alpha = 10\n",
    "- beta = 1\n",
    "- weight decay = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4646810a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = moddim_valtrain_5f\n",
    "test_df = moddim_valtest\n",
    "column_names = test_df.drop(columns = [\"persistence_d365\",\"pid\"]).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "914fac1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "lr_init = 0.001\n",
    "es_thr = 100 \n",
    "es_active = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00179848",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters tuned in step 1\n",
    "encoder_layers = [moddims, 512, 512, 512, 512, 512]\n",
    "classifier_layers = [512, 512, 512, 1]\n",
    "latent_size = 2\n",
    "#Hyperparameters tuned in step 2\n",
    "w_decay = 1\n",
    "alpha = 10\n",
    "beta = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9be3e3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_df_moddim_data = pd.DataFrame(columns = [\"seed\", \"best_auroc_epoch\",\"best_loss_epoch\", \"accuracy\", \"auroc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "96ccdd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds_list = list(range(1,500,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73b863b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed is 1\n",
      "./net_weights/SVAE_models_15-05-2023_10-05-40/ directory is created\n",
      "15-05-2023_10-05-40_loss_logs directory is created under H:\\Projects\\My Thesis\\loss_values\\\n",
      "Accuracy Score on the test data is: 0.6210526315789474\n",
      "ROC-AUC Score on the test data is: 0.5946135516353435\n",
      "seed is 11\n",
      "Accuracy Score on the test data is: 0.6210526315789474\n",
      "ROC-AUC Score on the test data is: 0.6044669280141436\n",
      "seed is 21\n",
      "Accuracy Score on the test data is: 0.6210526315789474\n",
      "ROC-AUC Score on the test data is: 0.6162900188323917\n",
      "seed is 31\n",
      "Accuracy Score on the test data is: 0.6210526315789474\n",
      "ROC-AUC Score on the test data is: 0.6050626465275377\n",
      "seed is 41\n",
      "Accuracy Score on the test data is: 0.6210526315789474\n",
      "ROC-AUC Score on the test data is: 0.6043612360198317\n",
      "seed is 51\n",
      "Accuracy Score on the test data is: 0.6210526315789474\n",
      "ROC-AUC Score on the test data is: 0.6154156577885391\n",
      "seed is 61\n",
      "Accuracy Score on the test data is: 0.6195488721804512\n",
      "ROC-AUC Score on the test data is: 0.6093575848418463\n",
      "seed is 71\n",
      "Accuracy Score on the test data is: 0.6210526315789474\n",
      "ROC-AUC Score on the test data is: 0.6208924247665167\n",
      "seed is 81\n",
      "Accuracy Score on the test data is: 0.6210526315789474\n",
      "ROC-AUC Score on the test data is: 0.6164773819132173\n",
      "seed is 91\n",
      "Accuracy Score on the test data is: 0.6285714285714286\n",
      "ROC-AUC Score on the test data is: 0.5996915715438718\n",
      "seed is 101\n",
      "Accuracy Score on the test data is: 0.6210526315789474\n",
      "ROC-AUC Score on the test data is: 0.6107315807679005\n",
      "seed is 111\n",
      "Accuracy Score on the test data is: 0.637593984962406\n",
      "ROC-AUC Score on the test data is: 0.622679580306699\n",
      "seed is 121\n",
      "Accuracy Score on the test data is: 0.6210526315789474\n",
      "ROC-AUC Score on the test data is: 0.6021705292286406\n",
      "seed is 131\n",
      "Accuracy Score on the test data is: 0.6210526315789474\n",
      "ROC-AUC Score on the test data is: 0.6140032284100081\n",
      "seed is 141\n",
      "Accuracy Score on the test data is: 0.6210526315789474\n",
      "ROC-AUC Score on the test data is: 0.6139744033206502\n",
      "seed is 151\n",
      "Accuracy Score on the test data is: 0.6225563909774436\n",
      "ROC-AUC Score on the test data is: 0.6159249010338599\n",
      "seed is 161\n",
      "Accuracy Score on the test data is: 0.6210526315789474\n",
      "ROC-AUC Score on the test data is: 0.5977458780122219\n",
      "seed is 171\n",
      "Accuracy Score on the test data is: 0.6210526315789474\n",
      "ROC-AUC Score on the test data is: 0.6032082324455206\n",
      "seed is 181\n",
      "Accuracy Score on the test data is: 0.6210526315789474\n",
      "ROC-AUC Score on the test data is: 0.590015949882778\n",
      "seed is 191\n",
      "Accuracy Score on the test data is: 0.6255639097744361\n",
      "ROC-AUC Score on the test data is: 0.5927110957377301\n",
      "seed is 201\n",
      "Accuracy Score on the test data is: 0.6210526315789474\n",
      "ROC-AUC Score on the test data is: 0.6007725123947885\n",
      "seed is 211\n",
      "Accuracy Score on the test data is: 0.6210526315789474\n",
      "ROC-AUC Score on the test data is: 0.6154733079672546\n",
      "seed is 221\n",
      "Accuracy Score on the test data is: 0.6210526315789474\n",
      "ROC-AUC Score on the test data is: 0.6009454629309351\n",
      "seed is 231\n",
      "Accuracy Score on the test data is: 0.6225563909774436\n",
      "ROC-AUC Score on the test data is: 0.608286252354049\n",
      "seed is 241\n",
      "Accuracy Score on the test data is: 0.6210526315789474\n",
      "ROC-AUC Score on the test data is: 0.6023578923094661\n",
      "seed is 251\n",
      "Accuracy Score on the test data is: 0.6210526315789474\n",
      "ROC-AUC Score on the test data is: 0.5839098351204889\n",
      "seed is 261\n",
      "Accuracy Score on the test data is: 0.6255639097744361\n",
      "ROC-AUC Score on the test data is: 0.5906741227564472\n",
      "seed is 271\n",
      "Accuracy Score on the test data is: 0.6210526315789474\n",
      "ROC-AUC Score on the test data is: 0.6198835466389945\n",
      "seed is 281\n",
      "Accuracy Score on the test data is: 0.6210526315789474\n",
      "ROC-AUC Score on the test data is: 0.5969964256889196\n",
      "seed is 291\n",
      "Accuracy Score on the test data is: 0.6210526315789474\n",
      "ROC-AUC Score on the test data is: 0.6323071601521965\n",
      "seed is 301\n",
      "Accuracy Score on the test data is: 0.6210526315789474\n",
      "ROC-AUC Score on the test data is: 0.6062684960990046\n",
      "seed is 311\n",
      "Accuracy Score on the test data is: 0.6210526315789474\n",
      "ROC-AUC Score on the test data is: 0.5909527652869057\n",
      "seed is 321\n",
      "Accuracy Score on the test data is: 0.6210526315789474\n",
      "ROC-AUC Score on the test data is: 0.6191629194050501\n",
      "seed is 331\n",
      "Accuracy Score on the test data is: 0.6210526315789474\n",
      "ROC-AUC Score on the test data is: 0.6239286675122027\n",
      "seed is 341\n",
      "Accuracy Score on the test data is: 0.6210526315789474\n",
      "ROC-AUC Score on the test data is: 0.5994657750105692\n",
      "seed is 351\n",
      "Accuracy Score on the test data is: 0.6210526315789474\n",
      "ROC-AUC Score on the test data is: 0.6186344594334909\n",
      "seed is 361\n",
      "Accuracy Score on the test data is: 0.6210526315789474\n",
      "ROC-AUC Score on the test data is: 0.5915677005265383\n",
      "seed is 371\n",
      "Accuracy Score on the test data is: 0.6210526315789474\n",
      "ROC-AUC Score on the test data is: 0.6102944002459741\n",
      "seed is 381\n",
      "Accuracy Score on the test data is: 0.6210526315789474\n",
      "ROC-AUC Score on the test data is: 0.615377224336062\n",
      "seed is 391\n",
      "Accuracy Score on the test data is: 0.6210526315789474\n",
      "ROC-AUC Score on the test data is: 0.5954398708635997\n",
      "seed is 401\n",
      "Accuracy Score on the test data is: 0.6210526315789474\n",
      "ROC-AUC Score on the test data is: 0.5878396556362657\n",
      "seed is 411\n",
      "Accuracy Score on the test data is: 0.6210526315789474\n",
      "ROC-AUC Score on the test data is: 0.6103376378800108\n",
      "seed is 421\n",
      "Accuracy Score on the test data is: 0.6255639097744361\n",
      "ROC-AUC Score on the test data is: 0.5961220646450671\n",
      "seed is 431\n",
      "Accuracy Score on the test data is: 0.6210526315789474\n",
      "ROC-AUC Score on the test data is: 0.6269553018947693\n",
      "seed is 441\n",
      "Accuracy Score on the test data is: 0.6210526315789474\n",
      "ROC-AUC Score on the test data is: 0.6167512202621162\n",
      "seed is 451\n",
      "Accuracy Score on the test data is: 0.6210526315789474\n",
      "ROC-AUC Score on the test data is: 0.5957281217571775\n",
      "seed is 461\n",
      "Accuracy Score on the test data is: 0.6210526315789474\n",
      "ROC-AUC Score on the test data is: 0.6310868980360506\n",
      "seed is 471\n",
      "Accuracy Score on the test data is: 0.637593984962406\n",
      "ROC-AUC Score on the test data is: 0.5903666551366309\n",
      "seed is 481\n",
      "Accuracy Score on the test data is: 0.6210526315789474\n",
      "ROC-AUC Score on the test data is: 0.6131769091817518\n",
      "seed is 491\n",
      "Accuracy Score on the test data is: 0.6195488721804512\n",
      "ROC-AUC Score on the test data is: 0.5764729620661824\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "# dd/mm/YY H:M:S\n",
    "dt_string = now.strftime(\"%d-%m-%Y_%H-%M-%S\")\n",
    "seeds_corr_list = []\n",
    "\n",
    "for i, seed in enumerate(seeds_list):\n",
    "    print(\"seed is\", seed)\n",
    "    best_auroc_epoch, best_loss_epoch, acc_score, auroc_score, X_test, y_test, eval_z, eval_pred_labels, eval_pred_prob = model_test(device, \n",
    "           train_df, test_df, batch_size, w_decay, alpha, \n",
    "           beta, lr_init, encoder_layers, classifier_layers,latent_size, \n",
    "            epochs = 500, seed = seed, es_active = es_active, es_thr = es_thr, es_patience = 10, \n",
    "           datestring = dt_string, shuffling = False)\n",
    "    \n",
    "    #Creating new result row\n",
    "    results = [seed, best_auroc_epoch, best_loss_epoch, acc_score, auroc_score]\n",
    "    #adding created result row to the report\n",
    "    report_df_moddim_data.loc[len(report_df_moddim_data)] = results\n",
    "    #top variables correlated with latent features are calculated\n",
    "    latent_f_top_vars_list = latent_corr_calc(X_test, column_names, eval_z)\n",
    "    #adding the top variables calculated with the specified random seed\n",
    "    seeds_corr_list.append(latent_f_top_vars_list)\n",
    "    \n",
    " \n",
    "    \n",
    "current_dir = os.getcwd()\n",
    "report_folder = current_dir + \"\\hyperparameter_reports\\\\\"\n",
    "if not os.path.exists(report_folder):\n",
    "    os.mkdir(report_folder)\n",
    "    print(\"hyperparameter_reports directory is created under \" + current_dir)\n",
    "    \n",
    "report_df_moddim_data.to_csv(os.path.join(report_folder,\"moddim_data_valtest_report_\"+ dt_string +  \".txt\"), sep = \"\\t\", index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5e35da32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6063466120911642"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_df_moddim_data[\"auroc\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "892f56d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012664601485949263"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_df_moddim_data[\"auroc\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f4338a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The AUROC Performance of Best SVAE model on moderate-dimensional dataset over 50 seeds is: \n",
      "0.6063 +- 0.0127\n"
     ]
    }
   ],
   "source": [
    "print(\" The AUROC Performance of Best SVAE model on moderate-dimensional dataset over 50 seeds is: \")\n",
    "\n",
    "print(str(round(report_df_moddim_data[\"auroc\"].mean(),4)) + \" +- \" + str(round(report_df_moddim_data[\"auroc\"].std(), 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884a7891",
   "metadata": {},
   "source": [
    "### Correlation calculation between input variables and latent dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f10a9182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 variables correlated with latent feature 1 for random seed 1\n",
      "          Variable  AVG_abs_corr\n",
      "0        ICD10_S61      0.124191\n",
      "1        ICD10_A09      0.117072\n",
      "2        ICD10_N87      0.106052\n",
      "3        ICD10_R50      0.104959\n",
      "4      ATC10_A04AA      0.104132\n",
      "5        ICD01_Z09      0.102427\n",
      "6      ATC10_G04BD      0.101400\n",
      "7      ATC10_G03AA      0.100779\n",
      "8  prednisolone_m0      0.099080\n",
      "9      ATC10_J01EA      0.096286\n",
      "Top 10 variables correlated with latent feature 2 for random seed 1\n",
      "      Variable  AVG_abs_corr\n",
      "0  hosptime_10      0.254344\n",
      "1  ATC10_D02AE      0.220154\n",
      "2       haq_m0      0.183528\n",
      "3  ATC10_N05CF      0.179775\n",
      "4    ICD10_K57      0.177741\n",
      "5  hosptime_01      0.176591\n",
      "6    ICD10_I10      0.176181\n",
      "7  ATC10_B03BA      0.165237\n",
      "8  ATC01_A06AC      0.163508\n",
      "9    ICD10_Z71      0.162257\n",
      "Top 10 variables correlated with latent feature 1 averaged in 50 random seeds.\n",
      "             AVG_abs_corr\n",
      "hosptime_10      0.120195\n",
      "ATC10_C03CA      0.089073\n",
      "ATC10_B03BA      0.080915\n",
      "ATC10_N05CF      0.076689\n",
      "hosptime_01      0.076595\n",
      "ATC10_A06AD      0.075569\n",
      "ATC01_B03BA      0.074114\n",
      "ICD10_Z09        0.074041\n",
      "ICD10_N39        0.072984\n",
      "ATC01_A06AC      0.072344\n",
      "Top 10 variables correlated with latent feature 2 averaged in 50 random seeds.\n",
      "             AVG_abs_corr\n",
      "hosptime_10      0.070391\n",
      "ICD10_R10        0.058679\n",
      "ATC10_D02AE      0.058538\n",
      "ATC10_B03BA      0.056848\n",
      "ATC01_B03BA      0.055145\n",
      "hosptime_01      0.053827\n",
      "ATC10_Y92AD      0.053803\n",
      "ATC10_A06AD      0.052569\n",
      "ATC10_A01AA      0.052045\n",
      "ATC10_C03CA      0.051171\n"
     ]
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "latent_folder = current_dir + \"\\latent_variable_correlations\\\\\"\n",
    "if not os.path.exists(latent_folder):\n",
    "    os.mkdir(latent_folder)\n",
    "    print(\"hyperparameter_reports directory is created under \" + current_dir)\n",
    "    \n",
    "    \n",
    "top_amount = 10\n",
    "seed_lenght = len(seeds_list)    \n",
    "\n",
    "latent_total_corr_list = []\n",
    "#iterating over each latent variable\n",
    "for f in range(eval_z.shape[1]):\n",
    "    f_dict = {}\n",
    "    #iterating over correlation list of each random seed\n",
    "    for s, seed_corr in enumerate(seeds_corr_list):\n",
    "        if s == 0:\n",
    "            f_corr_seed1 = seed_corr[f].droplevel(level = 0).dropna()\n",
    "            f_corr_seed1 = pd.DataFrame({'Variable':f_corr_seed1.index, 'AVG_abs_corr':f_corr_seed1.values})\n",
    "            print(\"Top \"+ str(top_amount) + \" variables correlated with latent feature \" + str(f+1) + \" for random seed \" + str(seeds_list[s]))\n",
    "            f_corr_seed1_sorted = f_corr_seed1.sort_values(by = \"AVG_abs_corr\", ascending = False)[:top_amount]\n",
    "            print(f_corr_seed1_sorted)\n",
    "            f_corr_seed1_sorted.to_csv(os.path.join(latent_folder,\"moddim_top_\" + str(top_amount) + \"_correlations_with_latent_variable_\" + str(f+1) + \"_\"  + dt_string +  \"_no_shuffling_random_seed\" + str(seeds_list[s]) + \".txt\"), sep = \"\\t\", index = True)\n",
    "            \n",
    "        f_corr = seed_corr[f].droplevel(level = 0).dropna()\n",
    "        \n",
    "        for var_num in range(f_corr.size):\n",
    "            if f_corr.index[var_num] not in f_dict:\n",
    "                f_dict[f_corr.index[var_num]] = f_corr[var_num]\n",
    "            else:\n",
    "                f_dict[f_corr.index[var_num]] += f_corr[var_num]\n",
    "        \n",
    "    f_total_corr_df = pd.DataFrame.from_dict(f_dict, orient = \"index\").rename(columns = {0:\"AVG_abs_corr\"})\n",
    "    latent_total_corr_list.append(f_total_corr_df)\n",
    "    \n",
    "        \n",
    "        \n",
    "\n",
    "for i in range(len(latent_total_corr_list)):\n",
    "    latent_avg_corr = latent_total_corr_list[i] / seed_lenght \n",
    "    print(\"Top \"+ str(top_amount) + \" variables correlated with latent feature \" + str(i+1) + \" averaged in \" + str(seed_lenght) + \" random seeds.\")\n",
    "    latent_avg_corr_sorted = latent_avg_corr.sort_values(by = \"AVG_abs_corr\",ascending = False)[:top_amount]\n",
    "    print(latent_avg_corr_sorted)\n",
    "    \n",
    "    latent_avg_corr_sorted.to_csv(os.path.join(latent_folder,\"moddim_top_\" + str(top_amount) + \"_correlations_with_latent_variable_\" + str(i+1) + \"_\"  + dt_string +  \"_no_shuffling_\" + str(seed_lenght) + \" seeds\" + \".txt\"), sep = \"\\t\", index = True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
